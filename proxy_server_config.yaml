model_list:
# OpenAI Models
  - model_name: gpt-3.5-turbo
    litellm_params:
      model: openai/gpt-3.5-turbo
  - model_name: gpt-4o
    litellm_params:
      model: openai/gpt-4o
  - model_name: gpt-4-turbo
    litellm_params:
      model: openai/gpt-4-turbo
  - model_name: tts-1
    litellm_params:
      model: openai/tts-1
  - model_name: tts-1-hd
    litellm_params:
      model: openai/tts-1-hd
  - model_name: dall-e-2
    litellm_params:
      model: openai/dall-e-2
    model_info:
      mode: image_generation
  - model_name: dall-e-3
    litellm_params:
      model: openai/dall-e-3
    model_info:
      mode: image_generation
  - model_name: text-moderation-stable
    litellm_params:
      model: openai/text-moderation-stable
  - model_name: text-moderation-latest
    litellm_params:
      model: openai/text-moderation-latest
  - model_name: whisper-1
    litellm_params:
      model: openai/whisper-1
    model_info:
      mode: audio_transcription

# Vertex AI Models
  - model_name: gemini-1.5-flash-001
    litellm_params:
      model: vertex_ai/gemini-1.5-flash-001
  - model_name: gemini-1.5-pro-001
    litellm_params:
      model: vertex_ai/gemini-1.5-pro-001
  - model_name: gemini-experimental
    litellm_params:
      model: vertex_ai/gemini-experimental

# Gemini AI Models (aistudio.google.com)
  - model_name: gemini-1.5-flash
    litellm_params:
      model: gemini/gemini-1.5-flash
  - model_name: gemini-1.5-pro
    litellm_params:
      model: gemini/gemini-1.5-pro

# ANTHROPIC Models
  - model_name: claude-3-opus-20240229
    litellm_params:
      model: claude-3-opus-20240229
      api_key: os.environ/ANTHROPIC_API_KEY
  - model_name: claude-3-sonnet-20240229
    litellm_params:
      model: claude-3-sonnet-20240229
      api_key: os.environ/ANTHROPIC_API_KEY
  - model_name: claude-3-haiku-20240307
    litellm_params:
      model: claude-3-haiku-20240307
      api_key: os.environ/ANTHROPIC_API_KEY
  - model_name: claude-3-5-sonnet-20240620
    litellm_params:
      model: claude-3-5-sonnet-20240620
      api_key: os.environ/ANTHROPIC_API_KEY

# Mistral Models
  - model_name: mistral-small-latest
    litellm_params:
      model: mistral/mistral-small-latest
  - model_name: mistral-medium-latest
    litellm_params:
      model: mistral/mistral-medium-latest
  - model_name: mistral-large-latest
    litellm_params:
      model: mistral/mistral-large-latest
  - model_name: open-mistral-7b
    litellm_params:
      model: mistral/open-mistral-7b
  - model_name: open-mixtral-8x7b
    litellm_params:
      model: mistral/open-mixtral-8x7b
  - model_name: open-mixtral-8x22b
    litellm_params:
      model: mistral/open-mixtral-8x22b
  - model_name: codestral-latest
    litellm_params:
      model: mistral/codestral-latest

# OLLAMA Models
  - model_name: llama3
    litellm_params:
      model: ollama_chat/llama3
      api_base: 'http://host.docker.internal:11434'
  - model_name: 'phi3:14b'
    litellm_params:
      model: 'ollama_chat/phi3:14b'
      api_base: 'http://host.docker.internal:11434'
  - model_name: 'phi3:3.8b'
    litellm_params:
      model: 'ollama_chat/phi3:3.8b'
      api_base: 'http://host.docker.internal:11434'
  - model_name: 'aya:8b'
    litellm_params:
      model: 'ollama_chat/aya:8b'
      api_base: 'http://host.docker.internal:11434'
  - model_name: 'gemma2'
    litellm_params:
      model: 'ollama_chat/gemma2'
      api_base: 'http://host.docker.internal:11434'
  - model_name: 'moondream'
    litellm_params:
      model: 'ollama/moondream:1.8b-v2-q8_0'
      api_base: 'http://host.docker.internal:11434'
  - model_name: 'llava:7b'
    litellm_params:
      model: 'ollama/llava:7b'
      api_base: 'http://host.docker.internal:11434'
  - model_name: 'internlm2:7b'
    litellm_params:
      model: 'ollama_chat/internlm2:7b'
      api_base: 'http://host.docker.internal:11434'


# Groq Models
  - model_name: groq/llama3-70b
    litellm_params:
      model: groq/llama3-70b-8192
  - model_name: groq/llama3-8b
    litellm_params:
      model: groq/llama3-8b-8192
  - model_name: groq/gemma-7b
    litellm_params:
      model: groq/gemma-7b-it
  - model_name: groq/mixtral-8x7b
    litellm_params:
      model: groq/mixtral-8x7b-32768
      api_base: https://api.groq.com/openai/v1
  - model_name: groq/whisper-v3
    litellm_params:
      model: openai/whisper-large-v3
      api_key: os.environ/GROQ_API_KEY
      api_base: https://api.groq.com/openai/v1

litellm_settings:
  vertex_project: useful-atlas-421217
  vertex_location: us-central1
  drop_params: true
  modify_params: true
  allowed_fails: 3 # cooldown model if it fails > 1 call in a minute. 
  cooldown_time: 30 # how long to cooldown model if fails/min > allowed_fails
  num_retries: 3